[train] #train parameters
epoch = 16
batch_size = 2

shuffle = True

reader_num = 8

optimizer = adam
learning_rate = 1e-3
weight_decay = 0
step_size = 1
lr_multiplier = 1

max_len=512
mlm_prob=0.15

[eval] #eval parameters
batch_size = 128

shuffle = False

reader_num = 4

[distributed]
use = True
backend = nccl

[data] #data parameters
train_dataset_type = IndexedDataset
train_formatter_type = VanillaLFM
train_data = /data/disk1/private/xcj/LegalBert/data/IndexData/data_SS_document

valid_dataset_type = IndexedDataset
valid_formatter_type = VanillaLFM
valid_data = /data/disk1/private/xcj/LegalBert/data/IndexData/data_SS_document


[model] #model parameters
model_name = VanillaLFM

[output] #output parameters
output_time = 1
test_time = 1

model_path = /data/disk1/private/xcj/LegalBert/model
model_name = VanillaLFM

tensorboard_path = /data/disk1/private/xcj/LegalBert/tensorboard

output_function = Null
